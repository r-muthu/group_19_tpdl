{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbwchaos/group_19_tpdl/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import scipy.signal as sps\n",
    "import soundfile\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from speechbrain.inference.VAD import VAD\n",
    "\n",
    "# Define device for torch\n",
    "use_cuda = True\n",
    "print(\"CUDA is available:\", torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reencoding for indonesian done!\n",
      "reencoding for french done!\n",
      "reencoding for chinese done!\n",
      "reencoding for english done!\n",
      "reencoding done!\n",
      "resampling for indonesian done!\n",
      "resampling for french done!\n",
      "resampling for chinese done!\n",
      "resampling for english done!\n",
      "resampling done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbwchaos/group_19_tpdl/.venv/lib/python3.12/site-packages/speechbrain/utils/autocast.py:188: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n",
      "/home/dbwchaos/group_19_tpdl/.venv/lib/python3.12/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrograms for indonesian done!\n",
      "spectrograms for french done!\n",
      "spectrograms for chinese done!\n",
      "spectrograms for english done!\n",
      "all spectrograms done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def reencode(file_name: str, target_name: str):\n",
    "    \"\"\"reencodes the given .mp3 file to .wav\"\"\"\n",
    "    AudioSegment.from_mp3(file_name).export(target_name, format=\"wav\")\n",
    "\n",
    "def reencode_all():\n",
    "    \"\"\"reencodes all .mp3 files in data/mp3\"\"\"\n",
    "    for lang in os.listdir(\"data/mp3\"):\n",
    "        source_dir = \"data/mp3/\" + lang\n",
    "        target_dir = \"data/wav/\" + lang\n",
    "        try:\n",
    "            os.makedirs(target_dir)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        except:\n",
    "            raise ValueError(\"file system error\")\n",
    "\n",
    "        for file in os.listdir(source_dir):\n",
    "            if file.endswith(\".mp3\"):\n",
    "                try:\n",
    "                    reencode(source_dir + '/' + file, target_dir + '/' + file[:-3] + \"wav\")\n",
    "                except:\n",
    "                    print(file + \" in \" + source_dir + \" reencoding failed!\")\n",
    "\n",
    "        print(\"reencoding for \" + lang + \" done!\")\n",
    "    print(\"reencoding done!\")\n",
    "\n",
    "def resample(file_name: str, target: int):\n",
    "    \"\"\"resamples the given file to the target sample rate\"\"\"\n",
    "    wf, sr = torchaudio.load(file_name)\n",
    "    transform = torchaudio.transforms.Resample(sr, target)\n",
    "    new_wf = transform(wf)\n",
    "    torchaudio.save(file_name, new_wf, target)\n",
    "\n",
    "def resample_all(target: int):\n",
    "    \"\"\"resamples all .wav files in data/\"\"\"\n",
    "    for lang in os.listdir(\"data/wav\"):\n",
    "        source_dir = \"data/wav/\" + lang\n",
    "\n",
    "        # resample each wavfile\n",
    "        for file in os.listdir(source_dir):\n",
    "            if file.endswith(\".wav\"):\n",
    "                try:\n",
    "                    resample(source_dir + '/' + file, target)\n",
    "                except:\n",
    "                    print(file + \" in \" + source_dir + \" resampling failed!\")\n",
    "\n",
    "        print(\"resampling for \" + lang + \" done!\")\n",
    "    print(\"resampling done!\")\n",
    "\n",
    "def generate_spectrograms(length: float):\n",
    "    \"\"\"generates all spectrograms from data/\"\"\"\n",
    "    # load voice detection model to split audio\n",
    "    vad = VAD.from_hparams(source=\"speechbrain/vad-crdnn-libriparty\", savedir=\"pretrained_models/vad-crdnn-libriparty\")\n",
    "\n",
    "    for lang in os.listdir(\"data/wav\"):\n",
    "        source_dir = \"data/wav/\" + lang\n",
    "        target_dir = \"data/mel/\" + lang\n",
    "        try:\n",
    "            os.makedirs(target_dir)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        except:\n",
    "            raise ValueError(\"file system error\")\n",
    "        subseg_file_number = 0\n",
    "\n",
    "        for file in os.listdir(source_dir):\n",
    "            if file.endswith(\".wav\"):\n",
    "                # load audio file and get segments\n",
    "                file_path = source_dir + '/' + file\n",
    "                wf, sr = torchaudio.load(file_path)\n",
    "                sample_count = len(wf[0])\n",
    "                duration = sample_count / sr\n",
    "                maxseg_len = int(sr * length)\n",
    "                segments = get_boundaries(vad, file_path)\n",
    "\n",
    "                # split audio to valid sub-segments\n",
    "                for segment in segments:\n",
    "                    segment_len = segment[1] - segment[0]\n",
    "                    segstart_idx = int(sample_count * (segment[0] / duration))\n",
    "                    subseg_count = int(segment_len / length)\n",
    "\n",
    "                    for i in range(subseg_count):\n",
    "                        # extract segment and generate spectrogram\n",
    "                        subseg = wf[:, segstart_idx + i * maxseg_len:segstart_idx + (i + 1) * maxseg_len]\n",
    "                        subseg_spec = torchaudio.transforms.AmplitudeToDB()(to_spectrogram(subseg, sr)) # AmplitudeToDB gives log-mel spectrogram\n",
    "                        save_spectrogram(target_dir + '/' + lang + str(subseg_file_number) + \".npy\", subseg_spec)\n",
    "                        subseg_file_number += 1\n",
    "\n",
    "        print(\"spectrograms for \" + lang + \" done!\")\n",
    "    print(\"all spectrograms done!\")\n",
    "\n",
    "def get_boundaries(vad, file_name):\n",
    "    \"\"\"gets a tensor of pairs demarcating vocal segments from a model and file\"\"\"\n",
    "    return vad.get_speech_segments(file_name)\n",
    "\n",
    "def to_spectrogram(data, sr):\n",
    "    \"\"\"generates spectrogram from waveform slice\"\"\"\n",
    "    spec_transform = torchaudio.transforms.MelSpectrogram(sr, n_mels=128)\n",
    "    spec = spec_transform(data)\n",
    "    return spec\n",
    "\n",
    "def save_spectrogram(file_name, spec):\n",
    "    \"\"\"save spectrogram as npy image file\"\"\"\n",
    "    np.save(file_name, spec.numpy())\n",
    "\n",
    "def read_spectrogram(file_name):\n",
    "    \"\"\"reads a .npy spectrogram to a torch.Tensor\"\"\"\n",
    "    return torch.tensor(np.load(file_name))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # this script works; expecting all the mp3 audio input to be in `data/mp3/<lang>`\n",
    "    # it will iterate through all <lang> to generate the log-mel specs for each\n",
    "    reencode_all()\n",
    "    resample_all(16000)\n",
    "    generate_spectrograms(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
