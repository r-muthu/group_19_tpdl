{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbwchaos/group_19_tpdl-main/.venv/lib/python3.12/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "/home/dbwchaos/group_19_tpdl-main/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import scipy.signal as sps\n",
    "import soundfile\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from speechbrain.inference.VAD import VAD\n",
    "\n",
    "# # Define device for torch\n",
    "# use_cuda = True\n",
    "# print(\"CUDA is available:\", torch.cuda.is_available())\n",
    "# device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/mp3'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 113\u001b[39m\n\u001b[32m    108\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.tensor(np.load(file_name))\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    111\u001b[39m     \u001b[38;5;66;03m# this script works; expecting all the mp3 audio input to be in `data/mp3/<lang>`\u001b[39;00m\n\u001b[32m    112\u001b[39m     \u001b[38;5;66;03m# it will iterate through all <lang> to generate the log-mel specs for each\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m     \u001b[43mreencode_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    114\u001b[39m     resample_all(\u001b[32m16000\u001b[39m)\n\u001b[32m    115\u001b[39m     generate_spectrograms(\u001b[32m3\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mreencode_all\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreencode_all\u001b[39m():\n\u001b[32m      6\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"reencodes all .mp3 files in data/mp3\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m lang \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/mp3\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[32m      8\u001b[39m         source_dir = \u001b[33m\"\u001b[39m\u001b[33mdata/mp3/\u001b[39m\u001b[33m\"\u001b[39m + lang\n\u001b[32m      9\u001b[39m         target_dir = \u001b[33m\"\u001b[39m\u001b[33mdata/wav/\u001b[39m\u001b[33m\"\u001b[39m + lang\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/mp3'"
     ]
    }
   ],
   "source": [
    "\n",
    "def reencode(file_name: str, target_name: str):\n",
    "    \"\"\"reencodes the given .mp3 file to .wav\"\"\"\n",
    "    AudioSegment.from_mp3(file_name).export(target_name, format=\"wav\")\n",
    "\n",
    "def reencode_all():\n",
    "    \"\"\"reencodes all .mp3 files in data/mp3\"\"\"\n",
    "    for lang in os.listdir(\"data/mp3\"):\n",
    "        source_dir = \"data/mp3/\" + lang\n",
    "        target_dir = \"data/wav/\" + lang\n",
    "        try:\n",
    "            os.makedirs(target_dir)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        except:\n",
    "            raise ValueError(\"file system error\")\n",
    "\n",
    "        for file in os.listdir(source_dir):\n",
    "            if file.endswith(\".mp3\"):\n",
    "                try:\n",
    "                    reencode(source_dir + '/' + file, target_dir + '/' + file[:-3] + \"wav\")\n",
    "                except:\n",
    "                    print(file + \" in \" + source_dir + \" reencoding failed!\")\n",
    "\n",
    "        print(\"reencoding for \" + lang + \" done!\")\n",
    "    print(\"reencoding done!\")\n",
    "\n",
    "def resample(file_name: str, target: int):\n",
    "    \"\"\"resamples the given file to the target sample rate\"\"\"\n",
    "    wf, sr = torchaudio.load(file_name)\n",
    "    transform = torchaudio.transforms.Resample(sr, target)\n",
    "    new_wf = transform(wf)\n",
    "    torchaudio.save(file_name, new_wf, target)\n",
    "\n",
    "def resample_all(target: int):\n",
    "    \"\"\"resamples all .wav files in data/\"\"\"\n",
    "    for lang in os.listdir(\"data/wav\"):\n",
    "        source_dir = \"data/wav/\" + lang\n",
    "\n",
    "        # resample each wavfile\n",
    "        for file in os.listdir(source_dir):\n",
    "            if file.endswith(\".wav\"):\n",
    "                try:\n",
    "                    resample(source_dir + '/' + file, target)\n",
    "                except:\n",
    "                    print(file + \" in \" + source_dir + \" resampling failed!\")\n",
    "\n",
    "        print(\"resampling for \" + lang + \" done!\")\n",
    "    print(\"resampling done!\")\n",
    "\n",
    "def generate_spectrograms(length: float):\n",
    "    \"\"\"generates all spectrograms from data/\"\"\"\n",
    "    # load voice detection model to split audio\n",
    "    vad = VAD.from_hparams(source=\"speechbrain/vad-crdnn-libriparty\", savedir=\"pretrained_models/vad-crdnn-libriparty\")\n",
    "\n",
    "    for lang in os.listdir(\"data/wav\"):\n",
    "        source_dir = \"data/wav/\" + lang\n",
    "        target_dir = \"data/mel/\" + lang\n",
    "        try:\n",
    "            os.makedirs(target_dir)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        except:\n",
    "            raise ValueError(\"file system error\")\n",
    "        subseg_file_number = 0\n",
    "\n",
    "        for file in os.listdir(source_dir):\n",
    "            if file.endswith(\".wav\"):\n",
    "                # load audio file and get segments\n",
    "                file_path = source_dir + '/' + file\n",
    "                wf, sr = torchaudio.load(file_path)\n",
    "                sample_count = len(wf[0])\n",
    "                duration = sample_count / sr\n",
    "                maxseg_len = int(sr * length)\n",
    "                segments = get_boundaries(vad, file_path)\n",
    "\n",
    "                # split audio to valid sub-segments\n",
    "                for segment in segments:\n",
    "                    segment_len = segment[1] - segment[0]\n",
    "                    segstart_idx = int(sample_count * (segment[0] / duration))\n",
    "                    subseg_count = int(segment_len / length)\n",
    "\n",
    "                    for i in range(subseg_count):\n",
    "                        # extract segment and generate spectrogram\n",
    "                        subseg = wf[:, segstart_idx + i * maxseg_len:segstart_idx + (i + 1) * maxseg_len]\n",
    "                        subseg_spec = torchaudio.transforms.AmplitudeToDB()(to_spectrogram(subseg, sr)) # AmplitudeToDB gives log-mel spectrogram\n",
    "                        save_spectrogram(target_dir + '/' + lang + str(subseg_file_number) + \".npy\", subseg_spec)\n",
    "                        subseg_file_number += 1\n",
    "\n",
    "        print(\"spectrograms for \" + lang + \" done!\")\n",
    "    print(\"all spectrograms done!\")\n",
    "\n",
    "def get_boundaries(vad, file_name):\n",
    "    \"\"\"gets a tensor of pairs demarcating vocal segments from a model and file\"\"\"\n",
    "    return vad.get_speech_segments(file_name)\n",
    "\n",
    "def to_spectrogram(data, sr):\n",
    "    \"\"\"generates spectrogram from waveform slice\"\"\"\n",
    "    spec_transform = torchaudio.transforms.MelSpectrogram(sr, n_mels=128)\n",
    "    spec = spec_transform(data)\n",
    "    return spec\n",
    "\n",
    "def save_spectrogram(file_name, spec):\n",
    "    \"\"\"save spectrogram as npy image file\"\"\"\n",
    "    np.save(file_name, spec.numpy())\n",
    "\n",
    "def read_spectrogram(file_name):\n",
    "    \"\"\"reads a .npy spectrogram to a torch.Tensor\"\"\"\n",
    "    return torch.tensor(np.load(file_name))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # this script works; expecting all the mp3 audio input to be in `data/mp3/<lang>`\n",
    "    # it will iterate through all <lang> to generate the log-mel specs for each\n",
    "    reencode_all()\n",
    "    resample_all(16000)\n",
    "    generate_spectrograms(3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
