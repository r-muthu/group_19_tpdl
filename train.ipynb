{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0de771",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "# Numpy\n",
    "import numpy as np\n",
    "# Pandas\n",
    "import pandas as pd\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics.classification import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40ff43a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(32, 64, dtype = torch.double)\n",
    "        self.hidden2 = nn.Linear(64, 32, dtype = torch.double)\n",
    "        self.hidden3 = nn.Linear(32, 16, dtype = torch.double)\n",
    "        self.fc = nn.Linear(16, 1, dtype = torch.double)\n",
    "        self.activation = nn.GELU()\n",
    "        self.sigmoid = torch.sigmoid\n",
    "        self.loss = torch.nn.CrossEntropyLoss()\n",
    "        self.accuracy = Accuracy()\n",
    "\n",
    "    def forward(self, x):\n",
    "        z1 = self.hidden1(x)\n",
    "        a1 = self.activation(z1)\n",
    "\n",
    "        z2 = self.hidden2(a1)\n",
    "        a2 = self.activation(z2)\n",
    "\n",
    "        z3 = self.hidden3(a2)\n",
    "        a3 = self.activation(z3)\n",
    "\n",
    "        z4 = self.fc(a3)\n",
    "        a4 = self.sigmoid(z4)\n",
    "\n",
    "        return a4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6624bce",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e57df38",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def split_data(dataset):\n",
    "    # Split dataset into train, validation, and test sets\n",
    "    train_data, temp_data = train_test_split(dataset, test_size=0.3, shuffle=True)\n",
    "    valid_data, test_data = train_test_split(temp_data, test_size=0.5, shuffle=True)\n",
    "\n",
    "    # Define batch size for training, full batch for validation and testing\n",
    "    batch_size = 128\n",
    "\n",
    "    # Create DataLoader objects\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)  # Mini-batch for training\n",
    "    valid_loader = DataLoader(valid_data, batch_size=len(valid_data), shuffle=False)  # Full batch for validation\n",
    "    test_loader = DataLoader(test_data, batch_size=len(test_data), shuffle=False)  # Full batch for testing\n",
    "\n",
    "    return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a1f243",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(train_loader, valid_loader, test_loader):\n",
    "    # Initialize model and optimizer\n",
    "    model = NeuralNetwork().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, betas=(0.9, 0.999), eps=1e-08)\n",
    "\n",
    "    # Early Stopping Parameters\n",
    "    best_val_loss = float('inf')  # Start with a large value\n",
    "    best_model_state = None\n",
    "    best_epoch = 0\n",
    "\n",
    "    num_epochs = 300\n",
    "    optimizer.zero_grad()\n",
    "    l2_lambda = 0.001  # L2 regularization strength\n",
    "\n",
    "    # Track previous losses to check overall improvement\n",
    "    prev_val_losses = []\n",
    "    stop_threshold = 5  # Number of times the loss can increase before stopping\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        for batch in train_loader:\n",
    "            inputs_batch, outputs_batch = batch\n",
    "            outputs_re = outputs_batch.to(device).reshape(-1, 1).to(dtype=torch.double)\n",
    "            inputs_re = inputs_batch.to(device).to(dtype=torch.double)\n",
    "\n",
    "            # Forward pass\n",
    "            pred = model(inputs_re)\n",
    "            loss_value = model.loss(pred.float(), outputs_re.float())\n",
    "\n",
    "            # Add L2 regularization (Ridge)\n",
    "            l2_norm = sum(p.pow(2).sum() for p in model.parameters())\n",
    "            loss_value = loss_value + l2_lambda * l2_norm\n",
    "\n",
    "            # Compute binary accuracy\n",
    "            accuracy_value = model.accuracy(pred, outputs_re)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # Validation step (full batch)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            inputs_valid, outputs_valid = next(iter(valid_loader))  # Full batch validation\n",
    "            inputs_valid = inputs_valid.to(device).to(dtype=torch.double)\n",
    "            outputs_valid = outputs_valid.to(device).reshape(-1, 1).to(dtype=torch.double)\n",
    "\n",
    "            pred_valid = model(inputs_valid)\n",
    "            val_loss = model.loss(pred_valid.float(), outputs_valid.float()).item()\n",
    "            val_accuracy = model.accuracy(pred_valid, outputs_valid)\n",
    "\n",
    "        # Store validation losses for trend analysis\n",
    "        prev_val_losses.append(val_loss)\n",
    "\n",
    "        # Save the best model based on the lowest validation loss\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            best_epoch = epoch + 1  # Store the epoch number (1-based index)\n",
    "\n",
    "            with open(\"best_model.pkl\", \"wb\") as f:\n",
    "                pickle.dump({\"model_state\": best_model_state, \"epoch\": best_epoch, \"val_loss\": best_val_loss}, f)\n",
    "\n",
    "        # Print progress\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {loss_value.item():.4f}, Training Accuracy: {accuracy_value.item():.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    # Load the best model and epoch based on validation loss\n",
    "    with open(\"best_model.pkl\", \"rb\") as f:\n",
    "        saved_data = pickle.load(f)\n",
    "        best_model_state = saved_data[\"model_state\"]\n",
    "        best_epoch = saved_data[\"epoch\"]\n",
    "        best_val_loss = saved_data[\"val_loss\"]\n",
    "\n",
    "        model.load_state_dict(best_model_state)  # Load the best model state into the model\n",
    "\n",
    "    print(f\"Best Model Achieved at Epoch: {best_epoch} with Validation Loss: {best_val_loss:.4f}\")\n",
    "\n",
    "    # Final Test Evaluation (full batch)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs_test, outputs_test = next(iter(test_loader))  # Full batch test\n",
    "        inputs_test = inputs_test.to(device).to(dtype=torch.double)\n",
    "        outputs_test = outputs_test.to(device).reshape(-1, 1).to(dtype=torch.double)\n",
    "\n",
    "        pred_test = model(inputs_test)\n",
    "        test_loss = model.loss(pred_test.float(), outputs_test.float()).item()\n",
    "        test_accuracy = model.accuracy(pred_test, outputs_test).item()\n",
    "\n",
    "    print(f'Final Test Loss: {test_loss:.4f}, Final Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "train_model(split_data(dataset))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
