{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: soundfile in c:\\users\\muthu\\anaconda3\\lib\\site-packages (0.13.1)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\muthu\\anaconda3\\lib\\site-packages (from soundfile) (1.16.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\muthu\\anaconda3\\lib\\site-packages (from soundfile) (1.26.4)\n",
      "Requirement already satisfied: pycparser in c:\\users\\muthu\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile) (2.21)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting speechbrain\n",
      "  Downloading speechbrain-1.0.3-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting hyperpyyaml (from speechbrain)\n",
      "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: joblib in c:\\users\\muthu\\anaconda3\\lib\\site-packages (from speechbrain) (1.4.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\muthu\\anaconda3\\lib\\site-packages (from speechbrain) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\muthu\\appdata\\roaming\\python\\python312\\site-packages (from speechbrain) (24.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\muthu\\anaconda3\\lib\\site-packages (from speechbrain) (1.13.1)\n",
      "Collecting sentencepiece (from speechbrain)\n",
      "  Downloading sentencepiece-0.2.0-cp312-cp312-win_amd64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: torch>=1.9 in c:\\users\\muthu\\anaconda3\\lib\\site-packages (from speechbrain) (2.6.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\muthu\\anaconda3\\lib\\site-packages (from speechbrain) (2.6.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\muthu\\anaconda3\\lib\\site-packages (from speechbrain) (4.66.4)\n",
      "Collecting huggingface_hub (from speechbrain)\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\muthu\\anaconda3\\lib\\site-packages (from torch>=1.9->speechbrain) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\muthu\\anaconda3\\lib\\site-packages (from torch>=1.9->speechbrain) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\muthu\\anaconda3\\lib\\site-packages (from torch>=1.9->speechbrain) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\muthu\\anaconda3\\lib\\site-packages (from torch>=1.9->speechbrain) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\muthu\\anaconda3\\lib\\site-packages (from torch>=1.9->speechbrain) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\muthu\\anaconda3\\lib\\site-packages (from torch>=1.9->speechbrain) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\muthu\\anaconda3\\lib\\site-packages (from torch>=1.9->speechbrain) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\muthu\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.9->speechbrain) (1.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\muthu\\anaconda3\\lib\\site-packages (from huggingface_hub->speechbrain) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\muthu\\anaconda3\\lib\\site-packages (from huggingface_hub->speechbrain) (2.32.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\muthu\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->speechbrain) (0.4.6)\n",
      "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain)\n",
      "  Using cached ruamel.yaml-0.18.10-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain)\n",
      "  Downloading ruamel.yaml.clib-0.2.12-cp312-cp312-win_amd64.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\muthu\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.9->speechbrain) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\muthu\\anaconda3\\lib\\site-packages (from requests->huggingface_hub->speechbrain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\muthu\\anaconda3\\lib\\site-packages (from requests->huggingface_hub->speechbrain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\muthu\\anaconda3\\lib\\site-packages (from requests->huggingface_hub->speechbrain) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\muthu\\anaconda3\\lib\\site-packages (from requests->huggingface_hub->speechbrain) (2024.7.4)\n",
      "Downloading speechbrain-1.0.3-py3-none-any.whl (864 kB)\n",
      "   ---------------------------------------- 0.0/864.1 kB ? eta -:--:--\n",
      "   --------------------------------------  860.2/864.1 kB 26.6 MB/s eta 0:00:01\n",
      "   --------------------------------------- 864.1/864.1 kB 18.2 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "   ---------------------------------------- 0.0/481.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 481.4/481.4 kB 15.2 MB/s eta 0:00:00\n",
      "Downloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
      "Downloading sentencepiece-0.2.0-cp312-cp312-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/992.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 992.0/992.0 kB 31.7 MB/s eta 0:00:00\n",
      "Using cached ruamel.yaml-0.18.10-py3-none-any.whl (117 kB)\n",
      "Downloading ruamel.yaml.clib-0.2.12-cp312-cp312-win_amd64.whl (115 kB)\n",
      "   ---------------------------------------- 0.0/115.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 115.5/115.5 kB 6.6 MB/s eta 0:00:00\n",
      "Installing collected packages: sentencepiece, ruamel.yaml.clib, ruamel.yaml, huggingface_hub, hyperpyyaml, speechbrain\n",
      "  Attempting uninstall: ruamel.yaml\n",
      "    Found existing installation: ruamel.yaml 0.17.21\n",
      "    Uninstalling ruamel.yaml-0.17.21:\n",
      "      Successfully uninstalled ruamel.yaml-0.17.21\n",
      "Successfully installed huggingface_hub-0.30.2 hyperpyyaml-1.2.2 ruamel.yaml-0.18.10 ruamel.yaml.clib-0.2.12 sentencepiece-0.2.0 speechbrain-1.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SpeechBrain could not find any working torchaudio backend. Audio files may fail to load. Follow this link for instructions and troubleshooting: https://speechbrain.readthedocs.io/en/latest/audioloading.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available: False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import scipy.signal as sps\n",
    "%pip install soundfile\n",
    "import soundfile\n",
    "\n",
    "from pydub import AudioSegment\n",
    "%pip install speechbrain\n",
    "from speechbrain.inference.VAD import VAD\n",
    "\n",
    "# Define device for torch\n",
    "use_cuda = True\n",
    "print(\"CUDA is available:\", torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFmpeg path: None\n"
     ]
    }
   ],
   "source": [
    "from pydub.utils import which\n",
    "from pydub import AudioSegment\n",
    "\n",
    "AudioSegment.converter = \"/usr/bin/ffmpeg\"\n",
    "print(\"FFmpeg path:\", AudioSegment.converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muthu\\anaconda3\\Lib\\site-packages\\pydub\\utils.py:198: RuntimeWarning: Couldn't find ffprobe or avprobe - defaulting to ffprobe, but may not work\n",
      "  warn(\"Couldn't find ffprobe or avprobe - defaulting to ffprobe, but may not work\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common_voice_zh-CN_18524189.mp3 in data/mp3/cn reencoding failed due to [WinError 2] The system cannot find the file specified\n",
      "reencoding for cn done!\n",
      "common_voice_en_41910499.mp3 in data/mp3/en reencoding failed due to [WinError 2] The system cannot find the file specified\n",
      "reencoding for en done!\n",
      "reencoding done!\n",
      "resampling for cn done!\n",
      "resampling for en done!\n",
      "resampling done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muthu\\anaconda3\\Lib\\site-packages\\speechbrain\\utils\\fetching.py:151: UserWarning: Using SYMLINK strategy on Windows for fetching potentially requires elevated privileges and is not recommended. See `LocalStrategy` documentation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 1314] A required privilege is not held by the client: 'C:\\\\Users\\\\muthu\\\\.cache\\\\huggingface\\\\hub\\\\models--speechbrain--vad-crdnn-libriparty\\\\snapshots\\\\c5d5ae4fce161d94c3ab0286e32fb4a041a21a04\\\\hyperparams.yaml' -> 'c:\\\\Users\\\\muthu\\\\Downloads\\\\group_19_tpdl\\\\pretrained_models\\\\vad-crdnn-libriparty\\\\hyperparams.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 116\u001b[0m\n\u001b[0;32m    114\u001b[0m reencode_all()\n\u001b[0;32m    115\u001b[0m resample_all(\u001b[38;5;241m16000\u001b[39m)\n\u001b[1;32m--> 116\u001b[0m \u001b[43mgenerate_spectrograms\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 54\u001b[0m, in \u001b[0;36mgenerate_spectrograms\u001b[1;34m(length)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"generates all spectrograms from data/\"\"\"\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# load voice detection model to split audio\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m vad \u001b[38;5;241m=\u001b[39m \u001b[43mVAD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_hparams\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspeechbrain/vad-crdnn-libriparty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msavedir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpretrained_models/vad-crdnn-libriparty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lang \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/wav\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     57\u001b[0m     source_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/wav/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m lang\n",
      "File \u001b[1;32mc:\\Users\\muthu\\anaconda3\\Lib\\site-packages\\speechbrain\\inference\\interfaces.py:477\u001b[0m, in \u001b[0;36mPretrained.from_hparams\u001b[1;34m(cls, source, hparams_file, pymodule_file, overrides, savedir, use_auth_token, revision, download_only, huggingface_cache_dir, overrides_must_match, local_strategy, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_hparams\u001b[39m(\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    416\u001b[0m ):\n\u001b[0;32m    417\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fetch and load based from outside source based on HyperPyYAML file\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \n\u001b[0;32m    419\u001b[0m \u001b[38;5;124;03m    The source can be a location on the filesystem or online/huggingface\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;124;03m    Instance of cls\u001b[39;00m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 477\u001b[0m     hparams_local_path \u001b[38;5;241m=\u001b[39m \u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhparams_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43msavedir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msavedir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhuggingface_cache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhuggingface_cache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    488\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    489\u001b[0m         pymodule_local_path \u001b[38;5;241m=\u001b[39m fetch(\n\u001b[0;32m    490\u001b[0m             filename\u001b[38;5;241m=\u001b[39mpymodule_file,\n\u001b[0;32m    491\u001b[0m             source\u001b[38;5;241m=\u001b[39msource,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    498\u001b[0m             local_strategy\u001b[38;5;241m=\u001b[39mlocal_strategy,\n\u001b[0;32m    499\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\muthu\\anaconda3\\Lib\\site-packages\\speechbrain\\utils\\fetching.py:398\u001b[0m, in \u001b[0;36mfetch\u001b[1;34m(filename, source, savedir, overwrite, allow_updates, allow_network, save_filename, use_auth_token, revision, huggingface_cache_dir, local_strategy)\u001b[0m\n\u001b[0;32m    395\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found on HF hub\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m--> 398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlink_with_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfetched_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdestination\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_strategy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\muthu\\anaconda3\\Lib\\site-packages\\speechbrain\\utils\\fetching.py:162\u001b[0m, in \u001b[0;36mlink_with_strategy\u001b[1;34m(src, dst, local_strategy)\u001b[0m\n\u001b[0;32m    157\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetch: Local file found, creating symlink \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m -> \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m, src, dst\n\u001b[0;32m    159\u001b[0m     )\n\u001b[0;32m    161\u001b[0m     dst\u001b[38;5;241m.\u001b[39munlink(missing_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# remove link or delete file\u001b[39;00m\n\u001b[1;32m--> 162\u001b[0m     \u001b[43mdst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msymlink_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dst\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m local_strategy \u001b[38;5;129;01min\u001b[39;00m (LocalStrategy\u001b[38;5;241m.\u001b[39mCOPY, LocalStrategy\u001b[38;5;241m.\u001b[39mCOPY_SKIP_CACHE):\n",
      "File \u001b[1;32mc:\\Users\\muthu\\anaconda3\\Lib\\pathlib.py:1386\u001b[0m, in \u001b[0;36mPath.symlink_to\u001b[1;34m(self, target, target_is_directory)\u001b[0m\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(os, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msymlink\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1385\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mos.symlink() not available on this system\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1386\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msymlink\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_is_directory\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 1314] A required privilege is not held by the client: 'C:\\\\Users\\\\muthu\\\\.cache\\\\huggingface\\\\hub\\\\models--speechbrain--vad-crdnn-libriparty\\\\snapshots\\\\c5d5ae4fce161d94c3ab0286e32fb4a041a21a04\\\\hyperparams.yaml' -> 'c:\\\\Users\\\\muthu\\\\Downloads\\\\group_19_tpdl\\\\pretrained_models\\\\vad-crdnn-libriparty\\\\hyperparams.yaml'"
     ]
    }
   ],
   "source": [
    "\n",
    "def reencode(file_name: str, target_name: str):\n",
    "    \"\"\"reencodes the given .mp3 file to .wav\"\"\"\n",
    "    AudioSegment.from_mp3(file_name).export(target_name, format=\"wav\")\n",
    "\n",
    "def reencode_all():\n",
    "    \"\"\"reencodes all .mp3 files in data/mp3\"\"\"\n",
    "    for lang in os.listdir(\"data/mp3\"):\n",
    "        source_dir = \"data/mp3/\" + lang\n",
    "        target_dir = \"data/wav/\" + lang\n",
    "        try:\n",
    "            os.makedirs(target_dir)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        except:\n",
    "            raise ValueError(\"file system error\")\n",
    "\n",
    "        for file in os.listdir(source_dir):\n",
    "            if file.endswith(\".mp3\"):\n",
    "                try:\n",
    "                    reencode(source_dir + '/' + file, target_dir + '/' + file[:-3] + \"wav\")\n",
    "                except Exception as e:\n",
    "                    print(file + \" in \" + source_dir + \" reencoding failed due to\", e)\n",
    "                    break\n",
    "\n",
    "        print(\"reencoding for \" + lang + \" done!\")\n",
    "    print(\"reencoding done!\")\n",
    "\n",
    "def resample(file_name: str, target: int):\n",
    "    \"\"\"resamples the given file to the target sample rate\"\"\"\n",
    "    wf, sr = torchaudio.load(file_name)\n",
    "    transform = torchaudio.transforms.Resample(sr, target)\n",
    "    new_wf = transform(wf)\n",
    "    torchaudio.save(file_name, new_wf, target)\n",
    "\n",
    "def resample_all(target: int):\n",
    "    \"\"\"resamples all .wav files in data/\"\"\"\n",
    "    for lang in os.listdir(\"data/wav\"):\n",
    "        source_dir = \"data/wav/\" + lang\n",
    "\n",
    "        # resample each wavfile\n",
    "        for file in os.listdir(source_dir):\n",
    "            if file.endswith(\".wav\"):\n",
    "                try:\n",
    "                    resample(source_dir + '/' + file, target)\n",
    "                except:\n",
    "                    print(file + \" in \" + source_dir + \" resampling failed!\")\n",
    "\n",
    "        print(\"resampling for \" + lang + \" done!\")\n",
    "    print(\"resampling done!\")\n",
    "\n",
    "def generate_spectrograms(length: float):\n",
    "    \"\"\"generates all spectrograms from data/\"\"\"\n",
    "    # load voice detection model to split audio\n",
    "    vad = VAD.from_hparams(source=\"speechbrain/vad-crdnn-libriparty\", savedir=\"pretrained_models/vad-crdnn-libriparty\")\n",
    "\n",
    "    for lang in os.listdir(\"data/wav\"):\n",
    "        source_dir = \"data/wav/\" + lang\n",
    "        target_dir = \"data/mel/\" + lang\n",
    "        try:\n",
    "            os.makedirs(target_dir)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        except:\n",
    "            raise ValueError(\"file system error\")\n",
    "        subseg_file_number = 0\n",
    "\n",
    "        for file in os.listdir(source_dir):\n",
    "            if file.endswith(\".wav\"):\n",
    "                # load audio file and get segments\n",
    "                file_path = source_dir + '/' + file\n",
    "                wf, sr = torchaudio.load(file_path)\n",
    "                sample_count = len(wf[0])\n",
    "                duration = sample_count / sr\n",
    "                maxseg_len = int(sr * length)\n",
    "                segments = get_boundaries(vad, file_path)\n",
    "\n",
    "                # split audio to valid sub-segments\n",
    "                for segment in segments:\n",
    "                    segment_len = segment[1] - segment[0]\n",
    "                    segstart_idx = int(sample_count * (segment[0] / duration))\n",
    "                    subseg_count = int(segment_len / length)\n",
    "\n",
    "                    for i in range(subseg_count):\n",
    "                        # extract segment and generate spectrogram\n",
    "                        subseg = wf[:, segstart_idx + i * maxseg_len:segstart_idx + (i + 1) * maxseg_len]\n",
    "                        subseg_spec = torchaudio.transforms.AmplitudeToDB()(to_spectrogram(subseg, sr)) # AmplitudeToDB gives log-mel spectrogram\n",
    "                        save_spectrogram(target_dir + '/' + lang + str(subseg_file_number) + \".npy\", subseg_spec)\n",
    "                        subseg_file_number += 1\n",
    "\n",
    "        print(\"spectrograms for \" + lang + \" done!\")\n",
    "    print(\"all spectrograms done!\")\n",
    "\n",
    "def get_boundaries(vad, file_name):\n",
    "    \"\"\"gets a tensor of pairs demarcating vocal segments from a model and file\"\"\"\n",
    "    return vad.get_speech_segments(file_name)\n",
    "\n",
    "def to_spectrogram(data, sr):\n",
    "    \"\"\"generates spectrogram from waveform slice\"\"\"\n",
    "    spec_transform = torchaudio.transforms.MelSpectrogram(sr, n_mels=128)\n",
    "    spec = spec_transform(data)\n",
    "    return spec\n",
    "\n",
    "def save_spectrogram(file_name, spec):\n",
    "    \"\"\"save spectrogram as npy image file\"\"\"\n",
    "    np.save(file_name, spec.numpy())\n",
    "\n",
    "def read_spectrogram(file_name):\n",
    "    \"\"\"reads a .npy spectrogram to a torch.Tensor\"\"\"\n",
    "    return torch.tensor(np.load(file_name))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # this script works; expecting all the mp3 audio input to be in `data/mp3/<lang>`\n",
    "    # it will iterate through all <lang> to generate the log-mel specs for each\n",
    "    reencode_all()\n",
    "    resample_all(16000)\n",
    "    generate_spectrograms(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
